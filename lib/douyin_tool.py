#!/usr/bin/env python3
"""
æŠ–éŸ³å·¥å…· - ç‹¬ç«‹Pythonè„šæœ¬ç‰ˆæœ¬
æ”¯æŒæœç´¢è§†é¢‘ã€è·å–å†…å®¹ã€æŸ¥çœ‹è¯„è®ºç­‰åŠŸèƒ½
åŸºäºDrissionPageè¿›è¡Œç½‘é¡µè‡ªåŠ¨åŒ–æŠ“å–
"""

import asyncio
import json
import time
import os
import sys
import argparse
import logging
import random
from datetime import datetime
from urllib.parse import quote
from typing import Dict, List, Optional
import re

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥DrissionPage
try:
    from DrissionPage import ChromiumPage
    from DrissionPage.errors import ElementNotFoundError
    DRISSION_AVAILABLE = True
except ImportError:
    DRISSION_AVAILABLE = False
    logger.warning("DrissionPageæœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install DrissionPage")

# å°è¯•å¯¼å…¥BeautifulSoup
try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
except ImportError:
    BS4_AVAILABLE = False
    logger.warning("BeautifulSoup4æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install beautifulsoup4")


class DouyinApi:
    """æŠ–éŸ³APIå°è£…ç±»"""
    
    def __init__(self):
        self.page = None
        self.is_browser_open = False
    
    def init_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨ï¼ˆå¢å¼ºåæ£€æµ‹èƒ½åŠ›ï¼‰"""
        if not DRISSION_AVAILABLE:
            raise ImportError("DrissionPageæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨æµè§ˆå™¨åŠŸèƒ½")

        if self.page is None:
            logger.info("æ­£åœ¨åˆå§‹åŒ–æµè§ˆå™¨ï¼ˆåæ£€æµ‹æ¨¡å¼ï¼‰...")

            try:
                # é…ç½®æµè§ˆå™¨é€‰é¡¹
                from DrissionPage import ChromiumOptions
                options = ChromiumOptions()

                # ğŸ”¥ ä½¿ç”¨æ–°æ— å¤´æ¨¡å¼ï¼ˆæ›´éš¾è¢«æ£€æµ‹ï¼‰
                logger.info("å¯ç”¨æ–°ç‰ˆheadlessæ¨¡å¼ï¼ˆæ›´éš¾æ£€æµ‹ï¼‰")
                options.set_argument('--headless=new')

                # ğŸ”¥ æ ¸å¿ƒåæ£€æµ‹å‚æ•°
                options.set_argument('--disable-blink-features=AutomationControlled')
                options.set_argument('--disable-features=TranslateUI')
                options.set_argument('--disable-features=BlinkGenPropertyTrees')

                # æ’é™¤è‡ªåŠ¨åŒ–å¼€å…³
                options.set_argument('--disable-infobars')
                options.set_argument('--excludeSwitches=enable-automation')
                options.set_argument('--useAutomationExtension=false')

                # Docker/Linuxå¿…éœ€å‚æ•°
                options.set_argument('--no-sandbox')
                options.set_argument('--disable-dev-shm-usage')
                options.set_argument('--disable-gpu')
                options.set_argument('--disable-software-rasterizer')

                # ğŸ”¥ çª—å£å¤§å°ï¼ˆä½¿ç”¨å¸¸è§åˆ†è¾¨ç‡ï¼‰
                options.set_argument('--window-size=1920,1080')
                options.set_argument('--start-maximized')

                # è¯­è¨€å’Œå¹³å°è®¾ç½®
                options.set_argument('--lang=zh-CN')
                options.set_argument('--accept-lang=zh-CN,zh;q=0.9,en;q=0.8')

                # ç¦ç”¨å„ç§æ£€æµ‹ç‰¹å¾
                options.set_argument('--disable-notifications')
                options.set_argument('--disable-popup-blocking')
                options.set_argument('--disable-extensions')
                options.set_argument('--disable-background-networking')
                options.set_argument('--disable-sync')
                options.set_argument('--disable-translate')
                options.set_argument('--disable-features=TranslateUI')
                options.set_argument('--mute-audio')
                options.set_argument('--no-first-run')
                options.set_argument('--no-default-browser-check')
                options.set_argument('--disable-hang-monitor')
                options.set_argument('--disable-prompt-on-repost')
                options.set_argument('--disable-client-side-phishing-detection')
                options.set_argument('--disable-component-update')
                options.set_argument('--disable-default-apps')

                # è¯ä¹¦å’Œå®‰å…¨
                options.set_argument('--ignore-certificate-errors')
                options.set_argument('--ignore-ssl-errors')
                options.set_argument('--allow-running-insecure-content')

                # ğŸ”¥ æ›´çœŸå®çš„User-Agent
                options.set_user_agent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')

                logger.info("åˆ›å»ºChromiumPageå®ä¾‹...")
                self.page = ChromiumPage(addr_or_opts=options)
                self.is_browser_open = True

                # ğŸ”¥ æ³¨å…¥åæ£€æµ‹è„šæœ¬ï¼ˆéšè—webdriverç‰¹å¾ï¼‰
                logger.info("æ³¨å…¥åæ£€æµ‹è„šæœ¬...")
                try:
                    # å®Œæ•´çš„åæ£€æµ‹è„šæœ¬ - ä¸€æ¬¡æ€§æ³¨å…¥
                    stealth_js = """
                    // 1. éšè—webdriverå±æ€§
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });

                    // 2. æ¨¡æ‹ŸçœŸå®çš„pluginsæ•°ç»„
                    Object.defineProperty(navigator, 'plugins', {
                        get: () => {
                            const plugins = [
                                {name: 'Chrome PDF Plugin', filename: 'internal-pdf-viewer', description: 'Portable Document Format'},
                                {name: 'Chrome PDF Viewer', filename: 'mhjfbmdgcfjbbpaeojofohoefgiehjai', description: ''},
                                {name: 'Native Client', filename: 'internal-nacl-plugin', description: ''}
                            ];
                            plugins.length = 3;
                            return plugins;
                        }
                    });

                    // 3. æ¨¡æ‹ŸçœŸå®çš„languages
                    Object.defineProperty(navigator, 'languages', {
                        get: () => ['zh-CN', 'zh', 'en']
                    });

                    // 4. å®Œæ•´çš„chromeå¯¹è±¡
                    window.chrome = {
                        runtime: {
                            connect: function() {},
                            sendMessage: function() {},
                            onMessage: { addListener: function() {} }
                        },
                        loadTimes: function() {
                            return {
                                commitLoadTime: Date.now() / 1000 - 0.5,
                                connectionInfo: 'h2',
                                finishDocumentLoadTime: Date.now() / 1000 - 0.1,
                                finishLoadTime: Date.now() / 1000,
                                firstPaintAfterLoadTime: 0,
                                firstPaintTime: Date.now() / 1000 - 0.3,
                                navigationType: 'Other',
                                npnNegotiatedProtocol: 'h2',
                                requestTime: Date.now() / 1000 - 1,
                                startLoadTime: Date.now() / 1000 - 0.8,
                                wasAlternateProtocolAvailable: false,
                                wasFetchedViaSpdy: true,
                                wasNpnNegotiated: true
                            };
                        },
                        csi: function() {
                            return {
                                onloadT: Date.now(),
                                pageT: Date.now() - performance.timing.navigationStart,
                                startE: performance.timing.navigationStart,
                                tran: 15
                            };
                        },
                        app: {
                            isInstalled: false,
                            InstallState: {INSTALLED: 'installed', NOT_INSTALLED: 'not_installed'},
                            RunningState: {RUNNING: 'running', CANNOT_RUN: 'cannot_run'}
                        }
                    };

                    // 5. éšè—è‡ªåŠ¨åŒ–ç›¸å…³çš„å±æ€§
                    delete window.cdc_adoQpoasnfa76pfcZLmcfl_Array;
                    delete window.cdc_adoQpoasnfa76pfcZLmcfl_Promise;
                    delete window.cdc_adoQpoasnfa76pfcZLmcfl_Symbol;

                    // 6. ä¿®æ”¹permissions API
                    const originalQuery = window.navigator.permissions.query;
                    window.navigator.permissions.query = (parameters) => (
                        parameters.name === 'notifications' ?
                        Promise.resolve({ state: Notification.permission }) :
                        originalQuery(parameters)
                    );

                    // 7. æ¨¡æ‹ŸçœŸå®çš„ç¡¬ä»¶å¹¶å‘æ•°
                    Object.defineProperty(navigator, 'hardwareConcurrency', {
                        get: () => 8
                    });

                    // 8. æ¨¡æ‹ŸçœŸå®çš„è®¾å¤‡å†…å­˜
                    Object.defineProperty(navigator, 'deviceMemory', {
                        get: () => 8
                    });

                    // 9. éšè—è‡ªåŠ¨åŒ–æ ‡è®°
                    Object.defineProperty(navigator, 'maxTouchPoints', {
                        get: () => 0
                    });

                    // 10. ä¿®å¤ WebGL æŒ‡çº¹
                    const getParameter = WebGLRenderingContext.prototype.getParameter;
                    WebGLRenderingContext.prototype.getParameter = function(parameter) {
                        if (parameter === 37445) {
                            return 'Intel Inc.';
                        }
                        if (parameter === 37446) {
                            return 'Intel Iris OpenGL Engine';
                        }
                        return getParameter.apply(this, arguments);
                    };

                    console.log('Anti-detection script injected successfully');
                    """
                    self.page.run_js(stealth_js)
                    logger.info("åæ£€æµ‹è„šæœ¬æ³¨å…¥æˆåŠŸ")
                except Exception as js_error:
                    logger.warning(f"åæ£€æµ‹è„šæœ¬æ³¨å…¥å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰: {js_error}")

                logger.info("ç­‰å¾…æµè§ˆå™¨ç¨³å®š...")
                time.sleep(3)

                logger.info("æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆï¼ˆåæ£€æµ‹æ¨¡å¼ï¼‰")

            except Exception as init_error:
                logger.error(f"æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {type(init_error).__name__}: {str(init_error)}")
                import traceback
                logger.error(f"è¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}")
                raise

        return self.page
    
    def close_browser(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.page and self.is_browser_open:
            try:
                self.page.quit()
                logger.info("æµè§ˆå™¨å·²å…³é—­")
            except Exception as e:
                logger.error(f"å…³é—­æµè§ˆå™¨å¤±è´¥: {e}")
            finally:
                self.page = None
                self.is_browser_open = False
    
    def _check_for_captcha(self, page) -> bool:
        """æ£€æµ‹é¡µé¢æ˜¯å¦å‡ºç°éªŒè¯ç """
        try:
            page_title = page.title or ""
            page_html = page.html[:5000] if page.html else ""  # åªå–å‰5000å­—ç¬¦æ£€æµ‹

            # éªŒè¯ç å…³é”®è¯åˆ—è¡¨
            captcha_indicators = [
                "éªŒè¯ç ", "éªŒè¯ä¸­é—´é¡µ", "captcha", "verify",
                "TTGCaptcha", "verifycenter", "æ»‘å—", "äººæœºéªŒè¯"
            ]

            for indicator in captcha_indicators:
                if indicator.lower() in page_title.lower() or indicator.lower() in page_html.lower():
                    logger.warning(f"âš ï¸ æ£€æµ‹åˆ°éªŒè¯ç ç‰¹å¾: {indicator}")
                    return True

            # æ£€æŸ¥æ˜¯å¦æœ‰éªŒè¯ç iframe
            try:
                captcha_iframe = page.ele('css:iframe[src*="verify"]', timeout=1)
                if captcha_iframe:
                    logger.warning("âš ï¸ æ£€æµ‹åˆ°éªŒè¯ç iframe")
                    return True
            except:
                pass

            return False
        except Exception as e:
            logger.warning(f"éªŒè¯ç æ£€æµ‹å¼‚å¸¸: {e}")
            return False

    def _inject_stealth_on_page(self, page):
        """åœ¨é¡µé¢åŠ è½½åå†æ¬¡æ³¨å…¥åæ£€æµ‹è„šæœ¬"""
        try:
            stealth_js = """
            Object.defineProperty(navigator, 'webdriver', { get: () => undefined });
            if (!window.chrome) {
                window.chrome = { runtime: {}, app: {}, csi: function(){}, loadTimes: function(){} };
            }
            """
            page.run_js(stealth_js)
        except:
            pass

    async def _enter_video_detail(self, page, video_url: str) -> bool:
        """è¿›å…¥è§†é¢‘è¯¦æƒ…é¡µ"""
        try:
            logger.info(f"è¿›å…¥è§†é¢‘è¯¦æƒ…é¡µ: {video_url}")
            page.get(video_url)
            await asyncio.sleep(random.uniform(3, 5))
            self._inject_stealth_on_page(page)

            # æ£€æŸ¥æ˜¯å¦æˆåŠŸåŠ è½½
            page_title = page.title or ""
            if "éªŒè¯" in page_title or "captcha" in page_title.lower():
                logger.warning("è§†é¢‘è¯¦æƒ…é¡µè§¦å‘éªŒè¯ç ")
                return False

            logger.info(f"è§†é¢‘è¯¦æƒ…é¡µåŠ è½½æˆåŠŸï¼Œæ ‡é¢˜: {page_title}")
            return True
        except Exception as e:
            logger.error(f"è¿›å…¥è§†é¢‘è¯¦æƒ…é¡µå¤±è´¥: {e}")
            return False

    async def _trigger_comments_load(self, page) -> bool:
        """è§¦å‘è¯„è®ºåŠ è½½ - ç‚¹å‡»è¯„è®ºåŒºåŸŸ"""
        try:
            logger.info("å°è¯•è§¦å‘è¯„è®ºåŠ è½½...")

            # æ–¹æ³•1: ç‚¹å‡»è¯„è®ºå›¾æ ‡/æ•°å­—ï¼ˆå³ä¾§çš„è¯„è®ºæŒ‰é’®ï¼‰
            comment_selectors = [
                'css:div[data-e2e="comment-icon"]',
                'css:div[class*="comment"]',
                'css:span[class*="comment"]',
                'css:div[data-e2e="feed-comment-icon"]',
            ]

            for selector in comment_selectors:
                try:
                    elem = page.ele(selector, timeout=2)
                    if elem:
                        logger.info(f"æ‰¾åˆ°è¯„è®ºå…ƒç´ : {selector}")
                        elem.click()
                        await asyncio.sleep(2)
                        return True
                except:
                    continue

            # æ–¹æ³•2: ä½¿ç”¨JavaScriptç‚¹å‡»è¯„è®ºåŒºåŸŸ
            try:
                page.run_js("""
                    const commentBtn = document.querySelector('[data-e2e="comment-icon"]')
                        || document.querySelector('[class*="comment-icon"]')
                        || document.querySelector('[class*="CommentIcon"]');
                    if (commentBtn) commentBtn.click();
                """)
                await asyncio.sleep(2)
                return True
            except:
                pass

            logger.warning("æœªæ‰¾åˆ°è¯„è®ºè§¦å‘å…ƒç´ ï¼Œå°è¯•ç›´æ¥æ»šåŠ¨åˆ°è¯„è®ºåŒº")
            return True  # ç»§ç»­å°è¯•

        except Exception as e:
            logger.error(f"è§¦å‘è¯„è®ºåŠ è½½å¤±è´¥: {e}")
            return False

    async def _click_continue_comments(self, page) -> bool:
        """ç‚¹å‡»"ç»§ç»­çœ‹è¯„è®º"å±•å¼€æ›´å¤šè¯„è®º"""
        try:
            logger.info("å°è¯•ç‚¹å‡»'ç»§ç»­çœ‹è¯„è®º'...")

            # ä»æˆªå›¾çœ‹åˆ°çš„é€‰æ‹©å™¨
            continue_selectors = [
                'css:div.related-video-card-login-guide__footer',
                'css:div[class*="footer-close"]',
                'css:div:contains("ç»§ç»­çœ‹è¯„è®º")',
                'xpath://div[contains(text(), "ç»§ç»­çœ‹è¯„è®º")]',
                'css:div[class*="login-guide"] div[class*="footer"]',
            ]

            for selector in continue_selectors:
                try:
                    elem = page.ele(selector, timeout=2)
                    if elem:
                        text = elem.text or ""
                        if "ç»§ç»­" in text or "è¯„è®º" in text or elem:
                            logger.info(f"æ‰¾åˆ°ç»§ç»­çœ‹è¯„è®ºå…ƒç´ : {selector}")
                            elem.click()
                            await asyncio.sleep(2)
                            return True
                except:
                    continue

            # ä½¿ç”¨JavaScriptæŸ¥æ‰¾å¹¶ç‚¹å‡»
            try:
                result = page.run_js("""
                    // æŸ¥æ‰¾åŒ…å«"ç»§ç»­çœ‹è¯„è®º"çš„å…ƒç´ 
                    const elements = document.querySelectorAll('div, span, p');
                    for (let elem of elements) {
                        if (elem.textContent && elem.textContent.includes('ç»§ç»­çœ‹è¯„è®º')) {
                            elem.click();
                            return true;
                        }
                    }
                    // æŸ¥æ‰¾ç™»å½•å¼•å¯¼çš„å…³é—­/ç»§ç»­æŒ‰é’®
                    const footerClose = document.querySelector('[class*="footer-close"]')
                        || document.querySelector('[class*="login-guide"] [class*="footer"]');
                    if (footerClose) {
                        footerClose.click();
                        return true;
                    }
                    return false;
                """)
                if result:
                    logger.info("é€šè¿‡JSç‚¹å‡»äº†ç»§ç»­çœ‹è¯„è®º")
                    await asyncio.sleep(2)
                    return True
            except:
                pass

            logger.warning("æœªæ‰¾åˆ°'ç»§ç»­çœ‹è¯„è®º'æŒ‰é’®")
            return False

        except Exception as e:
            logger.error(f"ç‚¹å‡»ç»§ç»­çœ‹è¯„è®ºå¤±è´¥: {e}")
            return False

    def _clean_comment_text(self, raw_text: str) -> str:
        """æ¸…æ´—è¯„è®ºæ–‡æœ¬ï¼Œç§»é™¤ç”¨æˆ·åã€æ—¶é—´ã€IPã€æ“ä½œæŒ‰é’®ç­‰æ— ç”¨ä¿¡æ¯"""
        if not raw_text:
            return ""

        text = raw_text.strip()

        # 1. ç§»é™¤å¼€å¤´çš„ç”¨æˆ·å (æ ¼å¼: @ç”¨æˆ·å æ•°å­—... æˆ– ç”¨æˆ·å æ•°å­—...)
        # åŒ¹é…: "@xxx 6 ..." æˆ– "xxx æ•°å­— ..."
        text = re.sub(r'^@?[\u4e00-\u9fa5\w\-_â–¡Â·.]+\s*\d*\s*\.{2,}\s*', '', text)

        # 2. ç§»é™¤æ—¶é—´ä¿¡æ¯ (Xåˆ†é’Ÿå‰, Xå°æ—¶å‰, Xå¤©å‰, Xå‘¨å‰, Xæœˆå‰, Xå¹´å‰, æ˜¨å¤©, åˆšåˆš)
        text = re.sub(r'\s*\d+[åˆ†å°æ—¶å¤©å‘¨æœˆå¹´]+å‰\s*', ' ', text)
        text = re.sub(r'\s*(æ˜¨å¤©|åˆšåˆš|ä»Šå¤©)\s*', ' ', text)

        # 3. ç§»é™¤IP/åœ°åŒºä¿¡æ¯ (Â·çœä»½/åŸå¸‚)
        text = re.sub(r'\s*[Â·â€¢]\s*[\u4e00-\u9fa5]{2,10}\s*', ' ', text)

        # 4. ç§»é™¤æ“ä½œæŒ‰é’®æ–‡æœ¬
        text = re.sub(r'\s*\d*\s*åˆ†äº«\s*', ' ', text)
        text = re.sub(r'\s*å›å¤\s*', ' ', text)
        text = re.sub(r'\s*å±•å¼€\d*æ¡å›å¤\s*', ' ', text)
        text = re.sub(r'\s*æ”¶èµ·å›å¤\s*', ' ', text)
        text = re.sub(r'\s*æŸ¥çœ‹æ›´å¤šå›å¤\s*', ' ', text)

        # 5. ç§»é™¤ç‚¹èµæ•° (å•ç‹¬çš„æ•°å­—)
        text = re.sub(r'\s+\d+\s*$', '', text)
        text = re.sub(r'^\d+\s+', '', text)

        # 6. ç§»é™¤"ä½œè€…"æ ‡è¯†
        text = re.sub(r'\s*ä½œè€…\s*', ' ', text)

        # 7. æ¸…ç†å¤šä½™ç©ºç™½
        text = re.sub(r'\s+', ' ', text).strip()

        return text

    async def _extract_comments(self, page, max_comments: int = 50) -> List[Dict]:
        """æå–è¯„è®ºæ•°æ®"""
        comments = []

        try:
            logger.info("å¼€å§‹æå–è¯„è®º...")

            # æ»šåŠ¨è¯„è®ºåŒºåŠ è½½æ›´å¤š
            for scroll_i in range(3):
                try:
                    page.run_js("""
                        const commentContainer = document.querySelector('[class*="comment-list"]')
                            || document.querySelector('[class*="CommentList"]')
                            || document.querySelector('[data-e2e="comment-list"]');
                        if (commentContainer) {
                            commentContainer.scrollTop += 500;
                        } else {
                            window.scrollBy(0, 300);
                        }
                    """)
                    await asyncio.sleep(1)
                except:
                    pass

            # ä½¿ç”¨JavaScriptæå–è¯„è®º
            js_extract_comments = """
            (function() {
                const comments = [];

                // æŸ¥æ‰¾è¯„è®ºé¡¹ - æ ¹æ®æˆªå›¾ä¸­çš„class
                const commentItems = document.querySelectorAll(
                    '[data-e2e="comment-item"], ' +
                    '[class*="comment-item"], ' +
                    '[class*="CommentItem"], ' +
                    'div[class*="xzjbH9qV"]'
                );

                commentItems.forEach(function(item, index) {
                    try {
                        // è·å–è¯„è®ºæ–‡æœ¬
                        let text = '';
                        const textElem = item.querySelector(
                            '[class*="comment-info-wrap"] span, ' +
                            '[class*="LvAtyU_f"] span, ' +
                            '[class*="j5WZzJdp"], ' +
                            'span[class*="sU2yAQQU"]'
                        );
                        if (textElem) {
                            text = textElem.textContent.trim();
                        }

                        // å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•è·å–æ•´ä¸ªè¯„è®ºåŒºåŸŸçš„æ–‡æœ¬
                        if (!text) {
                            const allSpans = item.querySelectorAll('span');
                            for (let span of allSpans) {
                                const spanText = span.textContent.trim();
                                if (spanText.length > 10 && spanText.length < 500) {
                                    text = spanText;
                                    break;
                                }
                            }
                        }

                        // è·å–ç”¨æˆ·å
                        let username = '';
                        const userElem = item.querySelector(
                            '[class*="comment-item-avatar"], ' +
                            '[class*="VPtAXFCJ"], ' +
                            '[class*="author"], ' +
                            '[class*="name"]'
                        );
                        if (userElem) {
                            username = userElem.textContent.trim();
                        }

                        // è·å–ç‚¹èµæ•°
                        let likes = '0';
                        const likesElem = item.querySelector('[class*="like"], [class*="count"]');
                        if (likesElem) {
                            const likesText = likesElem.textContent.trim();
                            if (/\\d/.test(likesText)) {
                                likes = likesText;
                            }
                        }

                        if (text && text.length > 2) {
                            comments.push({
                                text: text.substring(0, 500),
                                username: username || 'unknown',
                                likes: likes,
                                index: index
                            });
                        }
                    } catch(e) {}
                });

                return comments;
            })();
            """

            js_comments = page.run_js(js_extract_comments)

            if js_comments and len(js_comments) > 0:
                logger.info(f"JSæå–åˆ° {len(js_comments)} æ¡è¯„è®º")
                for c in js_comments[:max_comments]:
                    raw_text = c.get('text', '')
                    # æ¸…æ´—è¯„è®ºæ–‡æœ¬
                    cleaned_text = self._clean_comment_text(raw_text)
                    if cleaned_text and len(cleaned_text) > 2:
                        comments.append({
                            'text': cleaned_text,
                            'username': c.get('username', 'unknown'),
                            'likes': c.get('likes', '0'),
                            'collected_at': datetime.now().isoformat()
                        })
            else:
                logger.warning("JSæœªæå–åˆ°è¯„è®ºï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•...")

                # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨DrissionPageé€‰æ‹©å™¨
                try:
                    comment_elements = page.eles('css:div[data-e2e="comment-item"]', timeout=3)
                    if not comment_elements:
                        comment_elements = page.eles('css:div[class*="comment-item"]', timeout=2)

                    for elem in comment_elements[:max_comments]:
                        try:
                            raw_text = elem.text
                            if raw_text:
                                # æ¸…æ´—è¯„è®ºæ–‡æœ¬
                                cleaned_text = self._clean_comment_text(raw_text[:500])
                                if cleaned_text and len(cleaned_text) > 5:
                                    comments.append({
                                        'text': cleaned_text,
                                        'username': 'unknown',
                                        'likes': '0',
                                        'collected_at': datetime.now().isoformat()
                                    })
                        except:
                            continue
                except Exception as e:
                    logger.warning(f"å¤‡ç”¨æå–æ–¹æ³•å¤±è´¥: {e}")

            logger.info(f"å…±æå–åˆ° {len(comments)} æ¡è¯„è®º")

        except Exception as e:
            logger.error(f"æå–è¯„è®ºå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())

        return comments

    async def _get_video_with_comments(self, page, video_info: Dict) -> Dict:
        """è·å–å•ä¸ªè§†é¢‘çš„è¯¦æƒ…å’Œè¯„è®º"""
        video_url = video_info.get('video_url', '')
        if not video_url:
            return video_info

        try:
            # 1. è¿›å…¥è§†é¢‘è¯¦æƒ…é¡µ
            if not await self._enter_video_detail(page, video_url):
                logger.warning(f"æ— æ³•è¿›å…¥è§†é¢‘è¯¦æƒ…é¡µ: {video_url}")
                return video_info

            # 2. è·å–è§†é¢‘æè¿°ï¼ˆå¦‚æœæœ‰ï¼‰
            try:
                desc_js = """
                    const descElem = document.querySelector('[class*="desc"], [class*="title"], [class*="caption"]');
                    return descElem ? descElem.textContent.trim() : '';
                """
                description = page.run_js(desc_js)
                if description:
                    video_info['description'] = description[:500]
            except:
                pass

            # 3. è§¦å‘è¯„è®ºåŠ è½½
            await self._trigger_comments_load(page)

            # 4. ç‚¹å‡»"ç»§ç»­çœ‹è¯„è®º"ï¼ˆå¦‚æœæœ‰ç™»å½•å¼¹çª—ï¼‰
            await self._click_continue_comments(page)

            # 5. ç­‰å¾…è¯„è®ºåŠ è½½
            await asyncio.sleep(2)

            # 6. æå–è¯„è®º
            comments = await self._extract_comments(page)
            video_info['comments'] = comments
            video_info['comment_count'] = len(comments)

            logger.info(f"è§†é¢‘ [{video_info.get('title', '')[:30]}] è·å–åˆ° {len(comments)} æ¡è¯„è®º")

        except Exception as e:
            logger.error(f"è·å–è§†é¢‘è¯„è®ºå¤±è´¥: {e}")
            video_info['comments'] = []
            video_info['comment_count'] = 0

        return video_info

    async def search_videos(self, keyword: str, scroll_count: int = 5, delay: float = 2.0) -> List[Dict]:
        """æœç´¢æŠ–éŸ³è§†é¢‘ï¼ˆå¢å¼ºåæ£€æµ‹ç‰ˆæœ¬ï¼‰"""
        videos = []
        max_retries = 2  # æœ€å¤§é‡è¯•æ¬¡æ•°

        for retry in range(max_retries + 1):
            try:
                if retry > 0:
                    logger.info(f"ğŸ”„ ç¬¬ {retry} æ¬¡é‡è¯•...")
                    await asyncio.sleep(3)  # é‡è¯•å‰ç­‰å¾…

                # åˆå§‹åŒ–æµè§ˆå™¨
                logger.info("æ­¥éª¤1: åˆå§‹åŒ–æµè§ˆå™¨")
                page = self.init_browser()
                logger.info("æ­¥éª¤1å®Œæˆ: æµè§ˆå™¨åˆå§‹åŒ–æˆåŠŸ")

                # ğŸ”¥ å…ˆè®¿é—®æŠ–éŸ³é¦–é¡µï¼Œæ¨¡æ‹Ÿæ­£å¸¸ç”¨æˆ·è¡Œä¸º
                if retry == 0:
                    logger.info("æ­¥éª¤1.5: å…ˆè®¿é—®é¦–é¡µå»ºç«‹ä¼šè¯...")
                    try:
                        page.get("https://www.douyin.com/")
                        await asyncio.sleep(random.uniform(2, 4))
                        self._inject_stealth_on_page(page)
                    except:
                        pass

                # æ„å»ºæœç´¢URL
                search_url = f"https://www.douyin.com/search/{quote(keyword)}?source=normal_search&type=video"
                logger.info(f"æ­¥éª¤2: è®¿é—®æœç´¢é¡µé¢: {search_url}")

                # è®¿é—®é¡µé¢
                try:
                    logger.info("å¼€å§‹åŠ è½½é¡µé¢...")
                    page.get(search_url)
                    logger.info("é¡µé¢åŠ è½½å®Œæˆ")

                    # é¡µé¢åŠ è½½åå†æ¬¡æ³¨å…¥åæ£€æµ‹è„šæœ¬
                    self._inject_stealth_on_page(page)
                except Exception as page_error:
                    logger.error(f"é¡µé¢åŠ è½½å¤±è´¥: {type(page_error).__name__}: {str(page_error)}")
                    raise Exception(f"æ— æ³•è®¿é—®æŠ–éŸ³æœç´¢é¡µé¢: {str(page_error)}")

                # ğŸ”¥ ç­‰å¾…é¡µé¢æ¸²æŸ“ï¼ˆéšæœºæ—¶é—´ï¼Œæ›´åƒäººç±»ï¼‰
                wait_time = random.uniform(5, 8)
                logger.info(f"ç­‰å¾…é¡µé¢æ¸²æŸ“ï¼ˆ{wait_time:.1f}ç§’ï¼‰...")
                await asyncio.sleep(wait_time)

                # ğŸ”¥ æ£€æŸ¥é¡µé¢æ ‡é¢˜å’ŒéªŒè¯ç 
                try:
                    page_title = page.title
                    logger.info(f"é¡µé¢æ ‡é¢˜: {page_title}")
                except Exception as title_err:
                    logger.warning(f"è·å–æ ‡é¢˜å¤±è´¥: {title_err}")
                    page_title = ""

                # ğŸ”¥ éªŒè¯ç æ£€æµ‹
                if self._check_for_captcha(page):
                    logger.error("âŒ æ£€æµ‹åˆ°éªŒè¯ç é¡µé¢ï¼")
                    if retry < max_retries:
                        logger.info("å°è¯•å…³é—­æµè§ˆå™¨å¹¶é‡æ–°åˆå§‹åŒ–...")
                        self.close_browser()
                        continue  # é‡è¯•
                    else:
                        raise Exception("æŠ–éŸ³è§¦å‘äº†éªŒè¯ç æœºåˆ¶ï¼Œè¯·ç¨åé‡è¯•æˆ–ä½¿ç”¨å…¶ä»–IP")

                # ğŸ”¥ æ£€æŸ¥æ˜¯å¦çœŸçš„åŠ è½½äº†æœç´¢ç»“æœ
                if "æœç´¢" not in page_title and "æŠ–éŸ³" not in page_title:
                    logger.warning(f"âš ï¸ é¡µé¢æ ‡é¢˜å¼‚å¸¸: {page_title}")

                # ğŸ”¥ ç›´æ¥æå–æ•°æ®
                logger.info("æ­¥éª¤3: æå–è§†é¢‘æ•°æ®")
                seen_urls = set()
                videos = self._extract_video_data_direct(page, seen_urls)
                logger.info(f"æ­¥éª¤3å®Œæˆ: å…±é‡‡é›†åˆ° {len(videos)} æ¡è§†é¢‘æ•°æ®")

                # å¦‚æœæ²¡æœ‰ç»“æœä¸”æœªè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé‡è¯•
                if len(videos) == 0 and retry < max_retries:
                    logger.warning("æœªè·å–åˆ°è§†é¢‘æ•°æ®ï¼Œå‡†å¤‡é‡è¯•...")
                    self.close_browser()
                    continue

                break  # æˆåŠŸè·å–æ•°æ®ï¼Œé€€å‡ºé‡è¯•å¾ªç¯

            except Exception as e:
                logger.error(f"æœç´¢è§†é¢‘å¤±è´¥: {type(e).__name__}: {str(e)}")
                import traceback
                logger.error(f"è¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}")
                if retry >= max_retries:
                    raise
                else:
                    self.close_browser()
                    continue
            finally:
                # ç¡®ä¿æµè§ˆå™¨å…³é—­
                if retry >= max_retries or len(videos) > 0:
                    logger.info("æ¸…ç†: å…³é—­æµè§ˆå™¨")
                    self.close_browser()

        return videos

    async def search_videos_with_comments(self, keyword: str, max_videos: int = 10, max_comments_per_video: int = 30) -> List[Dict]:
        """æœç´¢è§†é¢‘å¹¶è·å–æ¯ä¸ªè§†é¢‘çš„è¯„è®ºï¼ˆæ·±åº¦æŠ“å–ç‰ˆæœ¬ï¼‰"""
        videos_with_comments = []

        try:
            # æ­¥éª¤1: åˆå§‹åŒ–æµè§ˆå™¨
            logger.info("=" * 50)
            logger.info("å¼€å§‹æ·±åº¦æŠ“å–ï¼ˆå«è¯„è®ºï¼‰")
            logger.info(f"å…³é”®è¯: {keyword}, æœ€å¤§è§†é¢‘æ•°: {max_videos}")
            logger.info("=" * 50)

            page = self.init_browser()

            # æ­¥éª¤2: å…ˆè®¿é—®é¦–é¡µå»ºç«‹ä¼šè¯
            logger.info("æ­¥éª¤1: è®¿é—®é¦–é¡µå»ºç«‹ä¼šè¯...")
            try:
                page.get("https://www.douyin.com/")
                await asyncio.sleep(random.uniform(3, 5))
                self._inject_stealth_on_page(page)
            except:
                pass

            # æ­¥éª¤3: è®¿é—®æœç´¢é¡µé¢è·å–è§†é¢‘åˆ—è¡¨
            search_url = f"https://www.douyin.com/search/{quote(keyword)}?source=normal_search&type=video"
            logger.info(f"æ­¥éª¤2: è®¿é—®æœç´¢é¡µé¢: {search_url}")

            page.get(search_url)
            await asyncio.sleep(random.uniform(5, 8))
            self._inject_stealth_on_page(page)

            # æ£€æŸ¥éªŒè¯ç 
            if self._check_for_captcha(page):
                raise Exception("æœç´¢é¡µé¢è§¦å‘éªŒè¯ç ï¼Œæ— æ³•ç»§ç»­")

            # æ­¥éª¤4: æå–è§†é¢‘åˆ—è¡¨
            logger.info("æ­¥éª¤3: æå–è§†é¢‘åˆ—è¡¨...")
            seen_urls = set()
            videos = self._extract_video_data_direct(page, seen_urls)
            logger.info(f"æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")

            if len(videos) == 0:
                logger.warning("æœªæ‰¾åˆ°è§†é¢‘ï¼Œè¯·æ£€æŸ¥æœç´¢å…³é”®è¯æˆ–åçˆ¬çŠ¶æ€")
                return []

            # é™åˆ¶è§†é¢‘æ•°é‡
            videos_to_process = videos[:max_videos]
            logger.info(f"å°†å¤„ç† {len(videos_to_process)} ä¸ªè§†é¢‘çš„è¯„è®º")

            # æ­¥éª¤5: é€ä¸ªè·å–è§†é¢‘è¯„è®º
            for idx, video in enumerate(videos_to_process):
                logger.info(f"\n{'='*30}")
                logger.info(f"å¤„ç†è§†é¢‘ {idx+1}/{len(videos_to_process)}: {video.get('title', '')[:40]}...")

                try:
                    # è·å–è¯„è®º
                    video_with_comments = await self._get_video_with_comments(page, video.copy())
                    videos_with_comments.append(video_with_comments)

                    # éšæœºå»¶è¿Ÿï¼Œé¿å…è¢«æ£€æµ‹
                    delay = random.uniform(3, 6)
                    logger.info(f"ç­‰å¾… {delay:.1f} ç§’åå¤„ç†ä¸‹ä¸€ä¸ª...")
                    await asyncio.sleep(delay)

                except Exception as e:
                    logger.error(f"å¤„ç†è§†é¢‘å¤±è´¥: {e}")
                    video['comments'] = []
                    video['comment_count'] = 0
                    videos_with_comments.append(video)

            logger.info(f"\n{'='*50}")
            logger.info(f"æ·±åº¦æŠ“å–å®Œæˆ!")
            total_comments = sum(v.get('comment_count', 0) for v in videos_with_comments)
            logger.info(f"å…±å¤„ç† {len(videos_with_comments)} ä¸ªè§†é¢‘ï¼Œè·å– {total_comments} æ¡è¯„è®º")
            logger.info("=" * 50)

        except Exception as e:
            logger.error(f"æ·±åº¦æŠ“å–å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
        finally:
            logger.info("æ¸…ç†: å…³é—­æµè§ˆå™¨")
            self.close_browser()

        return videos_with_comments
    
    async def _scroll_and_collect_videos(self, page, scroll_count: int, delay: float) -> List[Dict]:
        """æ»šåŠ¨é¡µé¢å¹¶æ”¶é›†è§†é¢‘æ•°æ®ï¼ˆä½¿ç”¨ç›´æ¥é€‰æ‹©å™¨ï¼Œé¿å…è·å–å®Œæ•´HTMLï¼‰"""
        collected = []
        seen_urls = set()

        try:
            # ã€è°ƒè¯•ã€‘è·å–åˆå§‹é¡µé¢çŠ¶æ€
            logger.info("ã€è°ƒè¯•ã€‘è·å–åˆå§‹é¡µé¢çŠ¶æ€...")
            initial_height = page.run_js("return document.body.scrollHeight")
            logger.info(f"ã€è°ƒè¯•ã€‘åˆå§‹é¡µé¢é«˜åº¦: {initial_height}")

            # ğŸ”¥ å°è¯•å…ˆæå–ä¸€æ¬¡æ•°æ®ï¼Œçœ‹çœ‹é€‰æ‹©å™¨æ˜¯å¦æ­£ç¡®
            logger.info("ã€è°ƒè¯•ã€‘æµ‹è¯•é€‰æ‹©å™¨...")
            new_videos = self._extract_video_data_direct(page, seen_urls)
            collected.extend(new_videos)
            logger.info(f"ã€è°ƒè¯•ã€‘åˆå§‹æå–åˆ° {len(new_videos)} æ¡è§†é¢‘")

            last_height = initial_height

            for i in range(scroll_count):
                logger.info(f"æ­£åœ¨æ»šåŠ¨é¡µé¢ {i+1}/{scroll_count}")

                # ğŸ”¥ æ¨¡æ‹ŸçœŸå®ç”¨æˆ·æ»šåŠ¨ï¼šåˆ†å¤šæ¬¡æ»šåŠ¨ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ»šåˆ°åº•
                scroll_steps = random.randint(3, 5)  # éšæœº3-5æ¬¡å°æ»šåŠ¨
                for step in range(scroll_steps):
                    scroll_amount = random.randint(300, 600)  # éšæœºæ»šåŠ¨è·ç¦»
                    page.run_js(f"window.scrollBy(0, {scroll_amount})")
                    await asyncio.sleep(random.uniform(0.3, 0.8))  # éšæœºçŸ­æš‚åœé¡¿

                # éšæœºç­‰å¾…æ—¶é—´ï¼Œæ¨¡æ‹ŸçœŸå®ç”¨æˆ·é˜…è¯»
                random_delay = delay + random.uniform(0, 1)
                logger.info(f"ç­‰å¾… {random_delay:.1f} ç§’...")
                await asyncio.sleep(random_delay)

                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾åº•éƒ¨
                new_height = page.run_js("return document.body.scrollHeight")
                logger.info(f"ã€è°ƒè¯•ã€‘æ»šåŠ¨åé¡µé¢é«˜åº¦: {new_height}, ä¹‹å‰é«˜åº¦: {last_height}")

                # ğŸ”¥ ç›´æ¥æå–è§†é¢‘æ•°æ®ï¼ˆä¸è·å–HTMLï¼‰
                new_videos = self._extract_video_data_direct(page, seen_urls)
                collected.extend(new_videos)
                logger.info(f"æœ¬æ¬¡æ»šåŠ¨æ–°å¢ {len(new_videos)} æ¡è§†é¢‘ï¼Œç´¯è®¡ {len(collected)} æ¡")

                if new_height == last_height:
                    logger.info("å·²åˆ°è¾¾é¡µé¢åº•éƒ¨")
                    break

                last_height = new_height

        except Exception as e:
            logger.error(f"æ»šåŠ¨é‡‡é›†å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}")

        return collected

    def _extract_video_data_direct(self, page, seen_urls: set) -> List[Dict]:
        """ç›´æ¥ä»é¡µé¢å…ƒç´ æå–è§†é¢‘æ•°æ®ï¼ˆæ”¹è¿›ç‰ˆæœ¬ï¼‰"""
        videos = []

        try:
            # ğŸ”¥ æ–¹æ³•1: ä½¿ç”¨JavaScriptç›´æ¥æå–æ‰€æœ‰è§†é¢‘é“¾æ¥ï¼ˆæœ€å¯é ï¼‰
            logger.info("ã€æ–¹æ³•1ã€‘ä½¿ç”¨JSæå–è§†é¢‘æ•°æ®...")
            try:
                js_extract = """
                (function() {
                    const results = [];
                    // æŸ¥æ‰¾æ‰€æœ‰åŒ…å« /video/ çš„é“¾æ¥
                    const links = document.querySelectorAll('a[href*="/video/"]');
                    links.forEach(function(link) {
                        const href = link.getAttribute('href');
                        if (href && href.includes('/video/')) {
                            // è·å–æ ‡é¢˜ - å°è¯•å¤šç§æ–¹å¼
                            let title = '';

                            // æ–¹å¼1: æŸ¥æ‰¾é“¾æ¥å†…çš„æ ‡é¢˜å…ƒç´ 
                            const titleElem = link.querySelector('p, span, div');
                            if (titleElem && titleElem.textContent) {
                                title = titleElem.textContent.trim();
                            }

                            // æ–¹å¼2: ä½¿ç”¨é“¾æ¥çš„titleå±æ€§
                            if (!title && link.title) {
                                title = link.title.trim();
                            }

                            // æ–¹å¼3: ä½¿ç”¨é“¾æ¥çš„æ–‡æœ¬å†…å®¹
                            if (!title && link.textContent) {
                                title = link.textContent.trim();
                            }

                            // æ–¹å¼4: æŸ¥æ‰¾çˆ¶å…ƒç´ ä¸­çš„æ–‡æœ¬
                            if (!title || title.length < 5) {
                                const parent = link.closest('li') || link.closest('div');
                                if (parent) {
                                    const allText = parent.textContent || '';
                                    if (allText.length > 5 && allText.length < 500) {
                                        title = allText.trim();
                                    }
                                }
                            }

                            // è·å–ä½œè€…ä¿¡æ¯
                            let author = '';
                            const parent = link.closest('li') || link.closest('div');
                            if (parent) {
                                const authorElem = parent.querySelector('[class*="author"], [class*="name"], [class*="user"]');
                                if (authorElem) {
                                    author = authorElem.textContent.trim();
                                }
                            }

                            // è·å–ç‚¹èµæ•°
                            let likes = '0';
                            if (parent) {
                                const likesElem = parent.querySelector('[class*="like"], [class*="count"]');
                                if (likesElem) {
                                    const likesText = likesElem.textContent.trim();
                                    if (/\\d/.test(likesText)) {
                                        likes = likesText;
                                    }
                                }
                            }

                            if (href && title && title.length > 3) {
                                results.push({
                                    href: href,
                                    title: title.substring(0, 200),
                                    author: author || 'unknown',
                                    likes: likes
                                });
                            }
                        }
                    });
                    return results;
                })();
                """
                js_results = page.run_js(js_extract)

                if js_results and len(js_results) > 0:
                    logger.info(f"ã€JSæå–ã€‘æ‰¾åˆ° {len(js_results)} æ¡è§†é¢‘æ•°æ®")

                    for item in js_results:
                        href = item.get('href', '')
                        if not href:
                            continue

                        # å¤„ç†URL
                        if href.startswith('//'):
                            video_url = 'https:' + href
                        elif href.startswith('/'):
                            video_url = 'https://www.douyin.com' + href
                        else:
                            video_url = href

                        # å»é‡
                        if video_url in seen_urls:
                            continue

                        video_data = {
                            'video_url': video_url,
                            'title': item.get('title', ''),
                            'author': item.get('author', 'unknown'),
                            'likes': item.get('likes', '0'),
                            'collected_at': datetime.now().isoformat()
                        }

                        videos.append(video_data)
                        seen_urls.add(video_url)

                        if len(videos) <= 5:
                            logger.info(f"ã€è°ƒè¯•ã€‘è§†é¢‘ {len(videos)}: {video_data.get('title', '')[:50]}")

                    if len(videos) > 0:
                        logger.info(f"ã€JSæ–¹æ³•æˆåŠŸã€‘å…±æå–åˆ° {len(videos)} æ¡æœ‰æ•ˆè§†é¢‘")
                        return videos

            except Exception as js_error:
                logger.warning(f"JSæå–å¤±è´¥: {js_error}")

            # ğŸ”¥ æ–¹æ³•2: ä½¿ç”¨DrissionPageé€‰æ‹©å™¨ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
            logger.info("ã€æ–¹æ³•2ã€‘ä½¿ç”¨é€‰æ‹©å™¨æå–...")

            # æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨åˆ—è¡¨
            selectors = [
                'css:a[href*="/video/"]',  # ç›´æ¥æ‰¾è§†é¢‘é“¾æ¥
                'css:li a[href*="/video/"]',  # liä¸­çš„è§†é¢‘é“¾æ¥
                'css:div[class*="video"] a',  # è§†é¢‘å®¹å™¨ä¸­çš„é“¾æ¥
                'css:ul li',  # åˆ—è¡¨é¡¹
            ]

            video_elements = []
            used_selector = ""

            for selector in selectors:
                try:
                    logger.info(f"ã€è°ƒè¯•ã€‘å°è¯•é€‰æ‹©å™¨: {selector}")
                    elements = page.eles(selector, timeout=3)
                    if elements and len(elements) > 0:
                        # è¿‡æ»¤ï¼šåªä¿ç•™åŒ…å«/video/é“¾æ¥çš„å…ƒç´ 
                        valid_elements = []
                        for elem in elements[:100]:  # æœ€å¤šæ£€æŸ¥100ä¸ª
                            try:
                                href = elem.attr('href') or ''
                                if '/video/' in href:
                                    valid_elements.append(elem)
                                else:
                                    # æ£€æŸ¥å­å…ƒç´ 
                                    sub_link = elem.ele('css:a[href*="/video/"]', timeout=0.3)
                                    if sub_link:
                                        valid_elements.append(elem)
                            except:
                                continue

                        if valid_elements:
                            logger.info(f"ã€é€‰æ‹©å™¨ {selector}ã€‘æ‰¾åˆ° {len(valid_elements)} ä¸ªæœ‰æ•ˆè§†é¢‘å…ƒç´ ")
                            video_elements = valid_elements
                            used_selector = selector
                            break
                        else:
                            logger.info(f"ã€é€‰æ‹©å™¨ {selector}ã€‘æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ï¼Œä½†æ— æœ‰æ•ˆè§†é¢‘")
                except Exception as sel_error:
                    logger.warning(f"é€‰æ‹©å™¨ {selector} å¤±è´¥: {sel_error}")
                    continue

            if not video_elements:
                logger.warning("ã€å¤±è´¥ã€‘æ‰€æœ‰é€‰æ‹©å™¨éƒ½æœªæ‰¾åˆ°æœ‰æ•ˆè§†é¢‘å…ƒç´ ")
                # ğŸ”¥ è°ƒè¯•ï¼šä¿å­˜é¡µé¢HTMLç”¨äºåˆ†æ
                try:
                    page_html = page.html[:10000] if page.html else ""
                    if "éªŒè¯" in page_html or "captcha" in page_html.lower():
                        logger.error("âŒ é¡µé¢åŒ…å«éªŒè¯ç ç›¸å…³å†…å®¹")
                    logger.info(f"ã€è°ƒè¯•ã€‘é¡µé¢HTMLå‰500å­—ç¬¦: {page_html[:500]}")
                except:
                    pass
                return []

            logger.info(f"å‡†å¤‡è§£æ {len(video_elements)} ä¸ªå…ƒç´ ")

            # è§£ææ¯ä¸ªå…ƒç´ 
            for idx, item in enumerate(video_elements[:50]):  # æœ€å¤šå¤„ç†50ä¸ª
                try:
                    video_data = {}

                    # è·å–é“¾æ¥
                    href = item.attr('href')
                    if not href or '/video/' not in href:
                        # å°è¯•æŸ¥æ‰¾å­é“¾æ¥
                        try:
                            link_elem = item.ele('css:a[href*="/video/"]', timeout=0.3)
                            if link_elem:
                                href = link_elem.attr('href')
                        except:
                            continue

                    if not href or '/video/' not in href:
                        continue

                    # å¤„ç†URL
                    if href.startswith('//'):
                        video_url = 'https:' + href
                    elif href.startswith('/'):
                        video_url = 'https://www.douyin.com' + href
                    else:
                        video_url = href

                    # å»é‡
                    if video_url in seen_urls:
                        continue

                    video_data['video_url'] = video_url

                    # è·å–æ ‡é¢˜
                    try:
                        text = item.text
                        if text and len(text.strip()) > 3:
                            video_data['title'] = text.strip()[:200]
                    except:
                        pass

                    video_data['collected_at'] = datetime.now().isoformat()
                    video_data['likes'] = '0'
                    video_data['author'] = 'unknown'

                    if video_data.get('title'):
                        videos.append(video_data)
                        seen_urls.add(video_url)
                        if len(videos) <= 5:
                            logger.info(f"ã€è°ƒè¯•ã€‘è§†é¢‘ {len(videos)}: {video_data.get('title', '')[:50]}")

                except Exception as item_error:
                    logger.debug(f"è§£æå…ƒç´  {idx} å¤±è´¥: {item_error}")
                    continue

            logger.info(f"ã€æˆåŠŸã€‘å…±æå–åˆ° {len(videos)} æ¡æœ‰æ•ˆè§†é¢‘")

        except Exception as e:
            logger.error(f"ç›´æ¥æå–è§†é¢‘æ•°æ®å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯:\n{traceback.format_exc()}")

        return videos

    def _extract_video_data(self, html_source: str, seen_urls: set) -> List[Dict]:
        """ä»HTMLä¸­æå–è§†é¢‘æ•°æ®"""
        if not BS4_AVAILABLE:
            logger.warning("BeautifulSoup4æœªå®‰è£…ï¼Œè·³è¿‡æ•°æ®æå–")
            return []

        videos = []

        try:
            soup = BeautifulSoup(html_source, 'html.parser')

            # æŸ¥æ‰¾è§†é¢‘é¡¹ç›®å®¹å™¨
            video_items = soup.select('li.SwZLHMKk')
            logger.info(f"ã€é€‰æ‹©å™¨ li.SwZLHMKkã€‘æ‰¾åˆ° {len(video_items)} ä¸ªè§†é¢‘é¡¹ç›®")

            # ã€è°ƒè¯•ã€‘å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–é€‰æ‹©å™¨
            if len(video_items) == 0:
                logger.warning("ã€è°ƒè¯•ã€‘æœªæ‰¾åˆ° li.SwZLHMKkï¼Œå°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„é€‰æ‹©å™¨...")
                # å°è¯•æŸ¥æ‰¾æ‰€æœ‰çš„liæ ‡ç­¾
                all_li = soup.find_all('li', limit=10)
                logger.info(f"ã€è°ƒè¯•ã€‘æ‰¾åˆ° {len(all_li)} ä¸ªliæ ‡ç­¾")
                if all_li:
                    for idx, li in enumerate(all_li[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                        logger.info(f"ã€è°ƒè¯•ã€‘li[{idx}] classes: {li.get('class', [])}")

                # å°è¯•æŸ¥æ‰¾åŒ…å«è§†é¢‘çš„å…¶ä»–å¸¸è§é€‰æ‹©å™¨
                alt_selectors = [
                    'li[class*="video"]',
                    'div[class*="video"]',
                    'a[href*="/video/"]',
                    'ul li',
                ]
                for selector in alt_selectors:
                    items = soup.select(selector)
                    if items:
                        logger.info(f"ã€è°ƒè¯•ã€‘é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(items)} ä¸ªå…ƒç´ ")
                        break
            
            for item in video_items:
                try:
                    video_data = {}
                    
                    # æå–æ ‡é¢˜
                    title_elem = item.select_one('div.VDYK8Xd7')
                    if title_elem:
                        video_data['title'] = title_elem.get_text(strip=True)
                    
                    # æå–ä½œè€…
                    author_elem = item.select_one('span.MZNczJmS')
                    if author_elem:
                        video_data['author'] = author_elem.get_text(strip=True)
                    
                    # æå–è§†é¢‘é“¾æ¥
                    link_elem = item.select_one('a.hY8lWHgA')
                    if link_elem:
                        href = link_elem.get('href', '')
                        if href.startswith('//'):
                            video_url = 'https:' + href
                        else:
                            video_url = href
                        video_data['video_url'] = video_url
                    else:
                        continue  # æ²¡æœ‰é“¾æ¥å°±è·³è¿‡
                    
                    # å»é‡æ£€æŸ¥
                    if video_data.get('video_url') in seen_urls:
                        continue
                    
                    # æå–å‘å¸ƒæ—¶é—´
                    time_elem = item.select_one('span.faDtinfi')
                    if time_elem:
                        video_data['publish_time'] = time_elem.get_text(strip=True)
                    
                    # æå–ç‚¹èµæ•°
                    likes_elem = item.select_one('span.cIiU4Muu')
                    if likes_elem:
                        video_data['likes'] = likes_elem.get_text(strip=True)
                    else:
                        video_data['likes'] = '0'
                    
                    # æ·»åŠ é‡‡é›†æ—¶é—´
                    video_data['collected_at'] = datetime.now().isoformat()
                    
                    # åªæ·»åŠ æœ‰æ ‡é¢˜çš„è§†é¢‘
                    if video_data.get('title'):
                        videos.append(video_data)
                        seen_urls.add(video_data.get('video_url'))
                
                except Exception as e:
                    logger.error(f"æå–å•ä¸ªè§†é¢‘æ•°æ®å¤±è´¥: {e}")
                    continue
        
        except Exception as e:
            logger.error(f"è§£æHTMLå¤±è´¥: {e}")
        
        return videos


class DouyinTool:
    """æŠ–éŸ³å·¥å…·ä¸»ç±»"""
    
    def __init__(self):
        self.api = DouyinApi()
    
    async def search_videos(self, keywords: str, scroll_count: int = 5) -> str:
        """æœç´¢è§†é¢‘å¹¶è¿”å›æ ¼å¼åŒ–ç»“æœ"""
        try:
            logger.info(f'æœç´¢å…³é”®è¯: {keywords}')
            videos = await self.api.search_videos(keywords, scroll_count)
            
            result = f"æœç´¢ç»“æœ - {keywords}ï¼š\n\n"
            
            if videos:
                for i, video in enumerate(videos[:20]):  # æœ€å¤šæ˜¾ç¤º20æ¡
                    title = video.get('title', 'N/A')
                    author = video.get('author', 'N/A')
                    likes = video.get('likes', '0')
                    url = video.get('video_url', '')
                    
                    result += f"{i+1}. {title}\n"
                    result += f"   ä½œè€…: {author}\n"
                    result += f"   ç‚¹èµæ•°: {likes}\n"
                    result += f"   é“¾æ¥: {url}\n\n"
            else:
                result = f"æœªæ‰¾åˆ°ä¸ \"{keywords}\" ç›¸å…³çš„è§†é¢‘"
            
            return result
        
        except Exception as e:
            logger.error(f"æœç´¢è§†é¢‘å¤±è´¥: {e}")
            return f"æœç´¢å¤±è´¥: {str(e)}"
    
    async def search_videos_raw(self, keywords: str, scroll_count: int = 5, limit: int = 20) -> Dict:
        """æœç´¢è§†é¢‘å¹¶è¿”å›åŸå§‹æ•°æ®ï¼ˆç”¨äºç¨‹åºè°ƒç”¨ï¼‰"""
        try:
            logger.info(f'æœç´¢å…³é”®è¯: {keywords}, é™åˆ¶: {limit}æ¡')
            videos = await self.api.search_videos(keywords, scroll_count)
            
            # é™åˆ¶è¿”å›æ•°é‡
            videos = videos[:limit]
            
            # æå–æ–‡æœ¬å†…å®¹
            raw_texts = []
            for video in videos:
                # æ·»åŠ æ ‡é¢˜
                if video.get('title'):
                    raw_texts.append(video['title'])
                
                # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šå†…å®¹æå–é€»è¾‘
                # ä¾‹å¦‚è§†é¢‘æè¿°ã€è¯„è®ºç­‰ï¼ˆéœ€è¦è¿›ä¸€æ­¥å®ç°ï¼‰
            
            return {
                'videos': videos,
                'raw_texts': raw_texts,
                'count': len(videos)
            }

        except Exception as e:
            logger.error(f"æœç´¢è§†é¢‘å¤±è´¥: {e}")
            raise

    async def search_videos_with_comments(self, keywords: str, max_videos: int = 10, max_comments: int = 30) -> Dict:
        """æœç´¢è§†é¢‘å¹¶è·å–è¯„è®ºï¼ˆæ·±åº¦æŠ“å–ç‰ˆæœ¬ï¼‰"""
        try:
            logger.info(f'æ·±åº¦æœç´¢å…³é”®è¯: {keywords}, æœ€å¤§è§†é¢‘æ•°: {max_videos}')
            videos = await self.api.search_videos_with_comments(keywords, max_videos, max_comments)

            # æå–æ‰€æœ‰æ–‡æœ¬ï¼ˆæ ‡é¢˜+è¯„è®ºï¼‰
            raw_texts = []
            all_comments = []

            for video in videos:
                # æ·»åŠ æ ‡é¢˜
                if video.get('title'):
                    raw_texts.append(video['title'])

                # æ·»åŠ æè¿°
                if video.get('description'):
                    raw_texts.append(video['description'])

                # æ·»åŠ è¯„è®º
                comments = video.get('comments', [])
                for comment in comments:
                    comment_text = comment.get('text', '')
                    if comment_text:
                        raw_texts.append(comment_text)
                        all_comments.append({
                            'video_title': video.get('title', ''),
                            'comment_text': comment_text,
                            'username': comment.get('username', 'unknown'),
                            'likes': comment.get('likes', '0')
                        })

            total_comments = sum(v.get('comment_count', 0) for v in videos)

            return {
                'videos': videos,
                'raw_texts': raw_texts,
                'all_comments': all_comments,
                'video_count': len(videos),
                'comment_count': total_comments
            }

        except Exception as e:
            logger.error(f"æ·±åº¦æœç´¢å¤±è´¥: {e}")
            raise


async def main():
    """ä¸»å‡½æ•°"""
    # ç¡®ä¿stdoutå’Œstderrä½¿ç”¨UTF-8ç¼–ç 
    if sys.stdout.encoding != 'utf-8':
        sys.stdout.reconfigure(encoding='utf-8')
    if sys.stderr.encoding != 'utf-8':
        sys.stderr.reconfigure(encoding='utf-8')

    parser = argparse.ArgumentParser(description='æŠ–éŸ³å·¥å…· - ç‹¬ç«‹Pythonè„šæœ¬ç‰ˆæœ¬')
    parser.add_argument('--action', type=str, required=True,
                        choices=['search', 'search-raw', 'search-with-comments'],
                        help='æ“ä½œç±»å‹: search(æ ¼å¼åŒ–è¾“å‡º), search-raw(åŸå§‹æ•°æ®), search-with-comments(å«è¯„è®ºæ·±åº¦æŠ“å–)')
    parser.add_argument('--keywords', type=str, help='æœç´¢å…³é”®è¯')
    parser.add_argument('--scroll-count', type=int, default=5, help='æ»šåŠ¨æ¬¡æ•°ï¼ˆé»˜è®¤5æ¬¡ï¼‰')
    parser.add_argument('--limit', type=int, default=20, help='è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼ˆé»˜è®¤20æ¡ï¼‰')
    parser.add_argument('--max-videos', type=int, default=10, help='æ·±åº¦æŠ“å–æ—¶çš„æœ€å¤§è§†é¢‘æ•°ï¼ˆé»˜è®¤10ï¼‰')
    parser.add_argument('--max-comments', type=int, default=30, help='æ¯ä¸ªè§†é¢‘çš„æœ€å¤§è¯„è®ºæ•°ï¼ˆé»˜è®¤30ï¼‰')

    args = parser.parse_args()

    # æ£€æŸ¥ä¾èµ–
    if not DRISSION_AVAILABLE:
        print("é”™è¯¯: DrissionPageæœªå®‰è£…", file=sys.stderr)
        print("è¯·è¿è¡Œ: pip install DrissionPage", file=sys.stderr)
        sys.exit(1)

    if not BS4_AVAILABLE:
        print("é”™è¯¯: BeautifulSoup4æœªå®‰è£…", file=sys.stderr)
        print("è¯·è¿è¡Œ: pip install beautifulsoup4", file=sys.stderr)
        sys.exit(1)

    # åˆå§‹åŒ–å·¥å…·
    tool = DouyinTool()

    try:
        if args.action == 'search':
            if not args.keywords:
                print("é”™è¯¯: æœç´¢æ“ä½œéœ€è¦æä¾› --keywords å‚æ•°", file=sys.stderr)
                sys.exit(1)
            result = await tool.search_videos(args.keywords, args.scroll_count)
            print(result)

        elif args.action == 'search-raw':
            if not args.keywords:
                print("é”™è¯¯: æœç´¢æ“ä½œéœ€è¦æä¾› --keywords å‚æ•°", file=sys.stderr)
                sys.exit(1)
            result = await tool.search_videos_raw(args.keywords, args.scroll_count, args.limit)
            # ç¡®ä¿è¾“å‡ºUTF-8ç¼–ç çš„JSONåˆ°stdout
            print(json.dumps(result, ensure_ascii=False, indent=2))

        elif args.action == 'search-with-comments':
            if not args.keywords:
                print("é”™è¯¯: æœç´¢æ“ä½œéœ€è¦æä¾› --keywords å‚æ•°", file=sys.stderr)
                sys.exit(1)
            logger.info(f"å¼€å§‹æ·±åº¦æŠ“å–ï¼Œå…³é”®è¯: {args.keywords}")
            result = await tool.search_videos_with_comments(
                args.keywords,
                max_videos=args.max_videos,
                max_comments=args.max_comments
            )
            # è¾“å‡ºç»“æœ
            print(json.dumps(result, ensure_ascii=False, indent=2))

    except Exception as e:
        logger.error(f"æ“ä½œå¤±è´¥: {e}")
        print(f"é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())

